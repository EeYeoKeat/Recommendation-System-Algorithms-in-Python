{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_RecSys_CF_Matrix_Factorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sePol42FUby3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-3mNH8HO5_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ee4a53-3413-4073-ecb0-dce3861fd58b"
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "!unzip ml-100k.zip\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 06:36:54--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  3.09MB/s    in 1.5s    \n",
            "\n",
            "2021-05-28 06:36:56 (3.09 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n",
            "ml-100k  ml-100k.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdgBgA0_Q5ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f06babb1-64dc-432e-a8bd-bdb1ddda203b"
      },
      "source": [
        "data = pd.read_csv(\"ml-100k/u1.base\", sep='\\t',names=\"userId,movieId,rating,timestamp\".split(\",\")) \n",
        "u1_data = data.copy()\n",
        "u1_data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>874965758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>876893171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>876893119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>889751712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79995</th>\n",
              "      <td>943</td>\n",
              "      <td>1067</td>\n",
              "      <td>2</td>\n",
              "      <td>875501756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79996</th>\n",
              "      <td>943</td>\n",
              "      <td>1074</td>\n",
              "      <td>4</td>\n",
              "      <td>888640250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79997</th>\n",
              "      <td>943</td>\n",
              "      <td>1188</td>\n",
              "      <td>3</td>\n",
              "      <td>888640250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79998</th>\n",
              "      <td>943</td>\n",
              "      <td>1228</td>\n",
              "      <td>3</td>\n",
              "      <td>888640275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79999</th>\n",
              "      <td>943</td>\n",
              "      <td>1330</td>\n",
              "      <td>3</td>\n",
              "      <td>888692465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating  timestamp\n",
              "0           1        1       5  874965758\n",
              "1           1        2       3  876893171\n",
              "2           1        3       4  878542960\n",
              "3           1        4       3  876893119\n",
              "4           1        5       3  889751712\n",
              "...       ...      ...     ...        ...\n",
              "79995     943     1067       2  875501756\n",
              "79996     943     1074       4  888640250\n",
              "79997     943     1188       3  888640250\n",
              "79998     943     1228       3  888640275\n",
              "79999     943     1330       3  888692465\n",
              "\n",
              "[80000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBa2fvLiRKh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e34e04-7d83-4f79-bb40-4fac7de080f1"
      },
      "source": [
        "user_ids = u1_data[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "print('This is user-to-encodeduser')\n",
        "print(list(user2user_encoded.items())[:10])\n",
        "\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "print('This is encodeduser-to-user')\n",
        "print(list(userencoded2user.items())[:10])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is user-to-encodeduser\n",
            "[(1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (10, 9)]\n",
            "This is encodeduser-to-user\n",
            "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCWkJ5vtuMAE",
        "outputId": "8b8b7fd1-8c8d-401f-91cb-9d77483dcc2a"
      },
      "source": [
        "movie_ids = np.arange(1, 1683)\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "print('This is encodedmovie-to-movie')\n",
        "print(list(movie2movie_encoded.items())[:10])\n",
        "\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "print('This is movie-to-encodedmovie')\n",
        "print(list(movie_encoded2movie.items())[:10])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is encodedmovie-to-movie\n",
            "[(1, 0), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (7, 6), (8, 7), (9, 8), (10, 9)]\n",
            "This is movie-to-encodedmovie\n",
            "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atfQ_6NrzY_R",
        "outputId": "45a40207-61cd-4eef-9861-fff8d82687a1"
      },
      "source": [
        "u1_data[\"user\"] = u1_data[\"userId\"].map(user2user_encoded)\n",
        "u1_data[\"movie\"] = u1_data[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "u1_data[\"rating\"] = u1_data[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "\n",
        "min_rating = min(u1_data[\"rating\"])\n",
        "max_rating = max(u1_data[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943, Number of Movies: 1682, Min rating: 1.0, Max rating: 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNMK_7oGRMWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5242e9-8bb4-4fef-b77c-d01ca9fa8b76"
      },
      "source": [
        "x = u1_data[[\"user\", \"movie\"]].values\n",
        "x"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0],\n",
              "       [   0,    1],\n",
              "       [   0,    2],\n",
              "       ...,\n",
              "       [ 942, 1187],\n",
              "       [ 942, 1227],\n",
              "       [ 942, 1329]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvqgyji5ZAyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342a33f9-61c0-4461-e975-48dcc4258b52"
      },
      "source": [
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = u1_data[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "y"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.  , 0.5 , 0.75, ..., 0.5 , 0.5 , 0.5 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "rK_YU0492L0r",
        "outputId": "c8d59f93-0cf2-44a6-c659-cc1a5594054d"
      },
      "source": [
        "test = pd.read_csv(\"ml-100k/u1.test\", sep='\\t',names=\"userId,movieId,rating,timestamp\".split(\",\"))\n",
        "test"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>458</td>\n",
              "      <td>648</td>\n",
              "      <td>4</td>\n",
              "      <td>886395899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>458</td>\n",
              "      <td>1101</td>\n",
              "      <td>4</td>\n",
              "      <td>886397931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>459</td>\n",
              "      <td>934</td>\n",
              "      <td>3</td>\n",
              "      <td>879563639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>460</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>882912371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>462</td>\n",
              "      <td>682</td>\n",
              "      <td>5</td>\n",
              "      <td>886365231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating  timestamp\n",
              "0           1        6       5  887431973\n",
              "1           1       10       3  875693118\n",
              "2           1       12       5  878542960\n",
              "3           1       14       5  874965706\n",
              "4           1       17       3  875073198\n",
              "...       ...      ...     ...        ...\n",
              "19995     458      648       4  886395899\n",
              "19996     458     1101       4  886397931\n",
              "19997     459      934       3  879563639\n",
              "19998     460       10       3  882912371\n",
              "19999     462      682       5  886365231\n",
              "\n",
              "[20000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LgG5Zzh62ia7",
        "outputId": "9d16a3ac-2ee5-4881-f190-7ab529a59e1b"
      },
      "source": [
        "test[\"user\"] = test[\"userId\"].map(user2user_encoded)\n",
        "test[\"movie\"] = test[\"movieId\"].map(movie2movie_encoded)\n",
        "test"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user</th>\n",
              "      <th>movie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>887431973</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>875693118</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>878542960</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>874965706</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>875073198</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>458</td>\n",
              "      <td>648</td>\n",
              "      <td>4</td>\n",
              "      <td>886395899</td>\n",
              "      <td>457</td>\n",
              "      <td>647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>458</td>\n",
              "      <td>1101</td>\n",
              "      <td>4</td>\n",
              "      <td>886397931</td>\n",
              "      <td>457</td>\n",
              "      <td>1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>459</td>\n",
              "      <td>934</td>\n",
              "      <td>3</td>\n",
              "      <td>879563639</td>\n",
              "      <td>458</td>\n",
              "      <td>933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>460</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>882912371</td>\n",
              "      <td>459</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>462</td>\n",
              "      <td>682</td>\n",
              "      <td>5</td>\n",
              "      <td>886365231</td>\n",
              "      <td>461</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating  timestamp  user  movie\n",
              "0           1        6       5  887431973     0      5\n",
              "1           1       10       3  875693118     0      9\n",
              "2           1       12       5  878542960     0     11\n",
              "3           1       14       5  874965706     0     13\n",
              "4           1       17       3  875073198     0     16\n",
              "...       ...      ...     ...        ...   ...    ...\n",
              "19995     458      648       4  886395899   457    647\n",
              "19996     458     1101       4  886397931   457   1100\n",
              "19997     459      934       3  879563639   458    933\n",
              "19998     460       10       3  882912371   459      9\n",
              "19999     462      682       5  886365231   461    681\n",
              "\n",
              "[20000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbBX_GS47yXi"
      },
      "source": [
        "x_test = test[[\"user\", \"movie\"]].values\n",
        "y_test = test[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXAY3FZS2D3Y"
      },
      "source": [
        "x_train = x\n",
        "x_val =  x_test\n",
        "y_train =  y\n",
        "y_val = y_test"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlHQ9z5DZNJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9116f45f-e7e7-48d0-8bc0-1c9c0ed53686"
      },
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        \n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuFjuAFoaSju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be0cfab-0438-4752-c05c-c93c56397aac"
      },
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6171 - val_loss: 0.6217\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6169 - val_loss: 0.6210\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6176 - val_loss: 0.6196\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6175 - val_loss: 0.6178\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6181 - val_loss: 0.6180\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6176 - val_loss: 0.6170\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6174 - val_loss: 0.6175\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6172 - val_loss: 0.6188\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6179 - val_loss: 0.6190\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6184 - val_loss: 0.6203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LxhxOpZgxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b1a7b78b-2944-4690-a621-e06a9f82a5fb"
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDRPn6AvaMkC"
      },
      "source": [
        "n_factors = 50\n",
        "\n",
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zL3Rn3BapTw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfb0c169-7d4c-4ada-d561-9bf74ecaa90e"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Reshape, Dot\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhGypxmAbszT"
      },
      "source": [
        "from keras.layers import Add, Activation, Lambda\n",
        "\n",
        "class EmbeddingLayer:\n",
        "    def __init__(self, n_items, n_factors):\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
        "                      embeddings_regularizer=l2(1e-6))(x)\n",
        "        x = Reshape((self.n_factors,))(x)\n",
        "        return x\n",
        "\n",
        "def RecommenderV2(n_users, n_movies, n_factors, min_rating, max_rating):\n",
        "    user = Input(shape=(1,))\n",
        "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
        "    ub = EmbeddingLayer(n_users, 1)(user)\n",
        "    \n",
        "    movie = Input(shape=(1,))\n",
        "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
        "    mb = EmbeddingLayer(n_movies, 1)(movie)\n",
        "\n",
        "    x = Dot(axes=1)([u, m])\n",
        "    x = Add()([x, ub, mb])\n",
        "    x = Activation('sigmoid')(x)\n",
        "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
        "\n",
        "    model = Model(inputs=[user, movie], outputs=x)\n",
        "    opt = Adam(lr=0.001)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs1OEbT8cIWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "8c66ece2-a495-4f9a-bdc5-79a69f0418b7"
      },
      "source": [
        "model = RecommenderV2(n_users, n_movies, n_factors, min_rating, max_rating)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 50)        30500       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 50)        486200      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 50)           0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 50)           0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 1)         610         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 1)         9724        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 1)            0           reshape_1[0][0]                  \n",
            "                                                                 reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 1)            0           dot_1[0][0]                      \n",
            "                                                                 reshape_2[0][0]                  \n",
            "                                                                 reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1)            0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 527,034\n",
            "Trainable params: 527,034\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu28qsWtcJ7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ae703f9-b3e2-47aa-f929-58fbd773d6cd"
      },
      "source": [
        "history = model.fit(x=X_train_array, y=y_train, batch_size=64, epochs=500,\n",
        "                    verbose=1, validation_data=(X_test_array, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 75627 samples, validate on 25209 samples\n",
            "Epoch 1/500\n",
            "75627/75627 [==============================] - 9s 117us/step - loss: 1.2574 - val_loss: 0.9033\n",
            "Epoch 2/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.7293 - val_loss: 0.7625\n",
            "Epoch 3/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.5393 - val_loss: 0.7379\n",
            "Epoch 4/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.4032 - val_loss: 0.7415\n",
            "Epoch 5/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.3066 - val_loss: 0.7558\n",
            "Epoch 6/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.2380 - val_loss: 0.7733\n",
            "Epoch 7/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.1896 - val_loss: 0.7934\n",
            "Epoch 8/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.1544 - val_loss: 0.8120\n",
            "Epoch 9/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.1283 - val_loss: 0.8321\n",
            "Epoch 10/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.1089 - val_loss: 0.8496\n",
            "Epoch 11/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0944 - val_loss: 0.8677\n",
            "Epoch 12/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0830 - val_loss: 0.8810\n",
            "Epoch 13/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0744 - val_loss: 0.8983\n",
            "Epoch 14/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0675 - val_loss: 0.9110\n",
            "Epoch 15/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0621 - val_loss: 0.9250\n",
            "Epoch 16/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0575 - val_loss: 0.9364\n",
            "Epoch 17/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0541 - val_loss: 0.9481\n",
            "Epoch 18/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0511 - val_loss: 0.9570\n",
            "Epoch 19/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0488 - val_loss: 0.9676\n",
            "Epoch 20/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0467 - val_loss: 0.9740\n",
            "Epoch 21/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0450 - val_loss: 0.9843\n",
            "Epoch 22/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0435 - val_loss: 0.9907\n",
            "Epoch 23/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0422 - val_loss: 0.9979\n",
            "Epoch 24/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0412 - val_loss: 1.0039\n",
            "Epoch 25/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0402 - val_loss: 1.0103\n",
            "Epoch 26/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0394 - val_loss: 1.0150\n",
            "Epoch 27/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0385 - val_loss: 1.0203\n",
            "Epoch 28/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0379 - val_loss: 1.0244\n",
            "Epoch 29/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0373 - val_loss: 1.0290\n",
            "Epoch 30/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0367 - val_loss: 1.0336\n",
            "Epoch 31/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0363 - val_loss: 1.0360\n",
            "Epoch 32/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0358 - val_loss: 1.0406\n",
            "Epoch 33/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0354 - val_loss: 1.0409\n",
            "Epoch 34/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0351 - val_loss: 1.0458\n",
            "Epoch 35/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0348 - val_loss: 1.0482\n",
            "Epoch 36/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0343 - val_loss: 1.0497\n",
            "Epoch 37/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0342 - val_loss: 1.0514\n",
            "Epoch 38/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0339 - val_loss: 1.0545\n",
            "Epoch 39/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0337 - val_loss: 1.0570\n",
            "Epoch 40/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0334 - val_loss: 1.0588\n",
            "Epoch 41/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0332 - val_loss: 1.0596\n",
            "Epoch 42/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0331 - val_loss: 1.0613\n",
            "Epoch 43/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0328 - val_loss: 1.0624\n",
            "Epoch 44/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0325 - val_loss: 1.0632\n",
            "Epoch 45/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0325 - val_loss: 1.0649\n",
            "Epoch 46/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0323 - val_loss: 1.0658\n",
            "Epoch 47/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0321 - val_loss: 1.0679\n",
            "Epoch 48/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0319 - val_loss: 1.0673\n",
            "Epoch 49/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0319 - val_loss: 1.0697\n",
            "Epoch 50/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0317 - val_loss: 1.0709\n",
            "Epoch 51/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0317 - val_loss: 1.0716\n",
            "Epoch 52/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0315 - val_loss: 1.0735\n",
            "Epoch 53/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0314 - val_loss: 1.0740\n",
            "Epoch 54/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0313 - val_loss: 1.0748\n",
            "Epoch 55/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0312 - val_loss: 1.0747\n",
            "Epoch 56/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0311 - val_loss: 1.0758\n",
            "Epoch 57/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0310 - val_loss: 1.0752\n",
            "Epoch 58/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0309 - val_loss: 1.0763\n",
            "Epoch 59/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0308 - val_loss: 1.0756\n",
            "Epoch 60/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0308 - val_loss: 1.0772\n",
            "Epoch 61/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0307 - val_loss: 1.0781\n",
            "Epoch 62/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0305 - val_loss: 1.0783\n",
            "Epoch 63/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0306 - val_loss: 1.0780\n",
            "Epoch 64/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0305 - val_loss: 1.0794\n",
            "Epoch 65/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0304 - val_loss: 1.0788\n",
            "Epoch 66/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0301 - val_loss: 1.0805\n",
            "Epoch 67/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0302 - val_loss: 1.0793\n",
            "Epoch 68/500\n",
            "75627/75627 [==============================] - 5s 60us/step - loss: 0.0302 - val_loss: 1.0798\n",
            "Epoch 69/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0301 - val_loss: 1.0809\n",
            "Epoch 70/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0300 - val_loss: 1.0807\n",
            "Epoch 71/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0299 - val_loss: 1.0805\n",
            "Epoch 72/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0298 - val_loss: 1.0829\n",
            "Epoch 73/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0299 - val_loss: 1.0811\n",
            "Epoch 74/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0298 - val_loss: 1.0825\n",
            "Epoch 75/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0297 - val_loss: 1.0821\n",
            "Epoch 76/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0296 - val_loss: 1.0838\n",
            "Epoch 77/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0296 - val_loss: 1.0821\n",
            "Epoch 78/500\n",
            "75627/75627 [==============================] - 5s 60us/step - loss: 0.0296 - val_loss: 1.0845\n",
            "Epoch 79/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0296 - val_loss: 1.0844\n",
            "Epoch 80/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0294 - val_loss: 1.0837\n",
            "Epoch 81/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0295 - val_loss: 1.0850\n",
            "Epoch 82/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0294 - val_loss: 1.0851\n",
            "Epoch 83/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0293 - val_loss: 1.0846\n",
            "Epoch 84/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0292 - val_loss: 1.0862\n",
            "Epoch 85/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0292 - val_loss: 1.0831\n",
            "Epoch 86/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0293 - val_loss: 1.0854\n",
            "Epoch 87/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0291 - val_loss: 1.0839\n",
            "Epoch 88/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0291 - val_loss: 1.0847\n",
            "Epoch 89/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0291 - val_loss: 1.0851\n",
            "Epoch 90/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0291 - val_loss: 1.0850\n",
            "Epoch 91/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0290 - val_loss: 1.0851\n",
            "Epoch 92/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0289 - val_loss: 1.0856\n",
            "Epoch 93/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0289 - val_loss: 1.0843\n",
            "Epoch 94/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0289 - val_loss: 1.0868\n",
            "Epoch 95/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0289 - val_loss: 1.0839\n",
            "Epoch 96/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0288 - val_loss: 1.0851\n",
            "Epoch 97/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0288 - val_loss: 1.0850\n",
            "Epoch 98/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0288 - val_loss: 1.0862\n",
            "Epoch 99/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0287 - val_loss: 1.0855\n",
            "Epoch 100/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0286 - val_loss: 1.0858\n",
            "Epoch 101/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0287 - val_loss: 1.0857\n",
            "Epoch 102/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0286 - val_loss: 1.0867\n",
            "Epoch 103/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0286 - val_loss: 1.0867\n",
            "Epoch 104/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0286 - val_loss: 1.0867\n",
            "Epoch 105/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0285 - val_loss: 1.0869\n",
            "Epoch 106/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0285 - val_loss: 1.0863\n",
            "Epoch 107/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0285 - val_loss: 1.0873\n",
            "Epoch 108/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0285 - val_loss: 1.0874\n",
            "Epoch 109/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0284 - val_loss: 1.0867\n",
            "Epoch 110/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0283 - val_loss: 1.0881\n",
            "Epoch 111/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0284 - val_loss: 1.0875\n",
            "Epoch 112/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0284 - val_loss: 1.0876\n",
            "Epoch 113/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0283 - val_loss: 1.0872\n",
            "Epoch 114/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0282 - val_loss: 1.0872\n",
            "Epoch 115/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0283 - val_loss: 1.0891\n",
            "Epoch 116/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0282 - val_loss: 1.0879\n",
            "Epoch 117/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0282 - val_loss: 1.0875\n",
            "Epoch 118/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0282 - val_loss: 1.0866\n",
            "Epoch 119/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0282 - val_loss: 1.0875\n",
            "Epoch 120/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0281 - val_loss: 1.0862\n",
            "Epoch 121/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0281 - val_loss: 1.0873\n",
            "Epoch 122/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0281 - val_loss: 1.0879\n",
            "Epoch 123/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0281 - val_loss: 1.0885\n",
            "Epoch 124/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0280 - val_loss: 1.0880\n",
            "Epoch 125/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0280 - val_loss: 1.0874\n",
            "Epoch 126/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0279 - val_loss: 1.0883\n",
            "Epoch 127/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0281 - val_loss: 1.0881\n",
            "Epoch 128/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0279 - val_loss: 1.0876\n",
            "Epoch 129/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0280 - val_loss: 1.0871\n",
            "Epoch 130/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0279 - val_loss: 1.0894\n",
            "Epoch 131/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0279 - val_loss: 1.0878\n",
            "Epoch 132/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0278 - val_loss: 1.0887\n",
            "Epoch 133/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0278 - val_loss: 1.0881\n",
            "Epoch 134/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0278 - val_loss: 1.0892\n",
            "Epoch 135/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0278 - val_loss: 1.0881\n",
            "Epoch 136/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0278 - val_loss: 1.0881\n",
            "Epoch 137/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0278 - val_loss: 1.0890\n",
            "Epoch 138/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0278 - val_loss: 1.0880\n",
            "Epoch 139/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0277 - val_loss: 1.0902\n",
            "Epoch 140/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0277 - val_loss: 1.0891\n",
            "Epoch 141/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0277 - val_loss: 1.0893\n",
            "Epoch 142/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0277 - val_loss: 1.0874\n",
            "Epoch 143/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0277 - val_loss: 1.0902\n",
            "Epoch 144/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0277 - val_loss: 1.0888\n",
            "Epoch 145/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0276 - val_loss: 1.0893\n",
            "Epoch 146/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0276 - val_loss: 1.0881\n",
            "Epoch 147/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0276 - val_loss: 1.0889\n",
            "Epoch 148/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0277 - val_loss: 1.0888\n",
            "Epoch 149/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0275 - val_loss: 1.0890\n",
            "Epoch 150/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0275 - val_loss: 1.0878\n",
            "Epoch 151/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0276 - val_loss: 1.0890\n",
            "Epoch 152/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0276 - val_loss: 1.0874\n",
            "Epoch 153/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0274 - val_loss: 1.0879\n",
            "Epoch 154/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0275 - val_loss: 1.0889\n",
            "Epoch 155/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0275 - val_loss: 1.0886\n",
            "Epoch 156/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0274 - val_loss: 1.0893\n",
            "Epoch 157/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0274 - val_loss: 1.0879\n",
            "Epoch 158/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0274 - val_loss: 1.0889\n",
            "Epoch 159/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0274 - val_loss: 1.0886\n",
            "Epoch 160/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0274 - val_loss: 1.0879\n",
            "Epoch 161/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0273 - val_loss: 1.0881\n",
            "Epoch 162/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0273 - val_loss: 1.0896\n",
            "Epoch 163/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0274 - val_loss: 1.0890\n",
            "Epoch 164/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0273 - val_loss: 1.0896\n",
            "Epoch 165/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0272 - val_loss: 1.0897\n",
            "Epoch 166/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0273 - val_loss: 1.0890\n",
            "Epoch 167/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0273 - val_loss: 1.0871\n",
            "Epoch 168/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0273 - val_loss: 1.0895\n",
            "Epoch 169/500\n",
            "75627/75627 [==============================] - 5s 60us/step - loss: 0.0272 - val_loss: 1.0887\n",
            "Epoch 170/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0272 - val_loss: 1.0887\n",
            "Epoch 171/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0273 - val_loss: 1.0886\n",
            "Epoch 172/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0272 - val_loss: 1.0887\n",
            "Epoch 173/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0272 - val_loss: 1.0894\n",
            "Epoch 174/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0273 - val_loss: 1.0887\n",
            "Epoch 175/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0888\n",
            "Epoch 176/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0889\n",
            "Epoch 177/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0886\n",
            "Epoch 178/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0272 - val_loss: 1.0886\n",
            "Epoch 179/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0271 - val_loss: 1.0879\n",
            "Epoch 180/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0270 - val_loss: 1.0888\n",
            "Epoch 181/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0890\n",
            "Epoch 182/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0884\n",
            "Epoch 183/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0270 - val_loss: 1.0897\n",
            "Epoch 184/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0270 - val_loss: 1.0880\n",
            "Epoch 185/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0270 - val_loss: 1.0883\n",
            "Epoch 186/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0271 - val_loss: 1.0889\n",
            "Epoch 187/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0271 - val_loss: 1.0885\n",
            "Epoch 188/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0270 - val_loss: 1.0886\n",
            "Epoch 189/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0269 - val_loss: 1.0892\n",
            "Epoch 190/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0270 - val_loss: 1.0896\n",
            "Epoch 191/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0270 - val_loss: 1.0883\n",
            "Epoch 192/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0269 - val_loss: 1.0894\n",
            "Epoch 193/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0269 - val_loss: 1.0894\n",
            "Epoch 194/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0886\n",
            "Epoch 195/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0885\n",
            "Epoch 196/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0269 - val_loss: 1.0870\n",
            "Epoch 197/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0896\n",
            "Epoch 198/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0269 - val_loss: 1.0885\n",
            "Epoch 199/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0886\n",
            "Epoch 200/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0881\n",
            "Epoch 201/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0882\n",
            "Epoch 202/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0268 - val_loss: 1.0893\n",
            "Epoch 203/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0269 - val_loss: 1.0883\n",
            "Epoch 204/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0268 - val_loss: 1.0884\n",
            "Epoch 205/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0268 - val_loss: 1.0878\n",
            "Epoch 206/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0267 - val_loss: 1.0890\n",
            "Epoch 207/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0268 - val_loss: 1.0881\n",
            "Epoch 208/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0268 - val_loss: 1.0887\n",
            "Epoch 209/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0268 - val_loss: 1.0867\n",
            "Epoch 210/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0899\n",
            "Epoch 211/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0268 - val_loss: 1.0876\n",
            "Epoch 212/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0885\n",
            "Epoch 213/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0878\n",
            "Epoch 214/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0894\n",
            "Epoch 215/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0880\n",
            "Epoch 216/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0267 - val_loss: 1.0888\n",
            "Epoch 217/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0895\n",
            "Epoch 218/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0267 - val_loss: 1.0895\n",
            "Epoch 219/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0267 - val_loss: 1.0889\n",
            "Epoch 220/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 1.0887\n",
            "Epoch 221/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0871\n",
            "Epoch 222/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0266 - val_loss: 1.0883\n",
            "Epoch 223/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0267 - val_loss: 1.0894\n",
            "Epoch 224/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0898\n",
            "Epoch 225/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0884\n",
            "Epoch 226/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0266 - val_loss: 1.0892\n",
            "Epoch 227/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0266 - val_loss: 1.0880\n",
            "Epoch 228/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0266 - val_loss: 1.0888\n",
            "Epoch 229/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0881\n",
            "Epoch 230/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0893\n",
            "Epoch 231/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0266 - val_loss: 1.0881\n",
            "Epoch 232/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0894\n",
            "Epoch 233/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0265 - val_loss: 1.0888\n",
            "Epoch 234/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0265 - val_loss: 1.0888\n",
            "Epoch 235/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0265 - val_loss: 1.0874\n",
            "Epoch 236/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0265 - val_loss: 1.0882\n",
            "Epoch 237/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0265 - val_loss: 1.0887\n",
            "Epoch 238/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0265 - val_loss: 1.0888\n",
            "Epoch 239/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0265 - val_loss: 1.0878\n",
            "Epoch 240/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0266 - val_loss: 1.0898\n",
            "Epoch 241/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0264 - val_loss: 1.0885\n",
            "Epoch 242/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0264 - val_loss: 1.0894\n",
            "Epoch 243/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0264 - val_loss: 1.0888\n",
            "Epoch 244/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0264 - val_loss: 1.0894\n",
            "Epoch 245/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0265 - val_loss: 1.0888\n",
            "Epoch 246/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0265 - val_loss: 1.0883\n",
            "Epoch 247/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0264 - val_loss: 1.0891\n",
            "Epoch 248/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0264 - val_loss: 1.0889\n",
            "Epoch 249/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0892\n",
            "Epoch 250/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0901\n",
            "Epoch 251/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0264 - val_loss: 1.0892\n",
            "Epoch 252/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0264 - val_loss: 1.0894\n",
            "Epoch 253/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0264 - val_loss: 1.0889\n",
            "Epoch 254/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0264 - val_loss: 1.0899\n",
            "Epoch 255/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0263 - val_loss: 1.0895\n",
            "Epoch 256/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0263 - val_loss: 1.0902\n",
            "Epoch 257/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0264 - val_loss: 1.0898\n",
            "Epoch 258/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0898\n",
            "Epoch 259/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0263 - val_loss: 1.0890\n",
            "Epoch 260/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0892\n",
            "Epoch 261/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0881\n",
            "Epoch 262/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0883\n",
            "Epoch 263/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0901\n",
            "Epoch 264/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0886\n",
            "Epoch 265/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0895\n",
            "Epoch 266/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0893\n",
            "Epoch 267/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0262 - val_loss: 1.0900\n",
            "Epoch 268/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0263 - val_loss: 1.0900\n",
            "Epoch 269/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0900\n",
            "Epoch 270/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0262 - val_loss: 1.0907\n",
            "Epoch 271/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0880\n",
            "Epoch 272/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0263 - val_loss: 1.0901\n",
            "Epoch 273/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0898\n",
            "Epoch 274/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0901\n",
            "Epoch 275/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0879\n",
            "Epoch 276/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0263 - val_loss: 1.0901\n",
            "Epoch 277/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0261 - val_loss: 1.0901\n",
            "Epoch 278/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0261 - val_loss: 1.0894\n",
            "Epoch 279/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0901\n",
            "Epoch 280/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0262 - val_loss: 1.0908\n",
            "Epoch 281/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0901\n",
            "Epoch 282/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0262 - val_loss: 1.0891\n",
            "Epoch 283/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0262 - val_loss: 1.0905\n",
            "Epoch 284/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0261 - val_loss: 1.0906\n",
            "Epoch 285/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0261 - val_loss: 1.0883\n",
            "Epoch 286/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0261 - val_loss: 1.0906\n",
            "Epoch 287/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0261 - val_loss: 1.0909\n",
            "Epoch 288/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0911\n",
            "Epoch 289/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0883\n",
            "Epoch 290/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0910\n",
            "Epoch 291/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0261 - val_loss: 1.0892\n",
            "Epoch 292/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0260 - val_loss: 1.0900\n",
            "Epoch 293/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0915\n",
            "Epoch 294/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0902\n",
            "Epoch 295/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0913\n",
            "Epoch 296/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0261 - val_loss: 1.0912\n",
            "Epoch 297/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0908\n",
            "Epoch 298/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0904\n",
            "Epoch 299/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0903\n",
            "Epoch 300/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0260 - val_loss: 1.0915\n",
            "Epoch 301/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0261 - val_loss: 1.0896\n",
            "Epoch 302/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0260 - val_loss: 1.0906\n",
            "Epoch 303/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0260 - val_loss: 1.0888\n",
            "Epoch 304/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0923\n",
            "Epoch 305/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0898\n",
            "Epoch 306/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0260 - val_loss: 1.0909\n",
            "Epoch 307/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0260 - val_loss: 1.0899\n",
            "Epoch 308/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0260 - val_loss: 1.0904\n",
            "Epoch 309/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0259 - val_loss: 1.0907\n",
            "Epoch 310/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0903\n",
            "Epoch 311/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0260 - val_loss: 1.0900\n",
            "Epoch 312/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0920\n",
            "Epoch 313/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0260 - val_loss: 1.0911\n",
            "Epoch 314/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0259 - val_loss: 1.0902\n",
            "Epoch 315/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0259 - val_loss: 1.0908\n",
            "Epoch 316/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0259 - val_loss: 1.0910\n",
            "Epoch 317/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0260 - val_loss: 1.0907\n",
            "Epoch 318/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0259 - val_loss: 1.0910\n",
            "Epoch 319/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0899\n",
            "Epoch 320/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0260 - val_loss: 1.0911\n",
            "Epoch 321/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0259 - val_loss: 1.0916\n",
            "Epoch 322/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0910\n",
            "Epoch 323/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0905\n",
            "Epoch 324/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0919\n",
            "Epoch 325/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0895\n",
            "Epoch 326/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0259 - val_loss: 1.0914\n",
            "Epoch 327/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0909\n",
            "Epoch 328/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0258 - val_loss: 1.0915\n",
            "Epoch 329/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0924\n",
            "Epoch 330/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0910\n",
            "Epoch 331/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0260 - val_loss: 1.0909\n",
            "Epoch 332/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0258 - val_loss: 1.0913\n",
            "Epoch 333/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0914\n",
            "Epoch 334/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0906\n",
            "Epoch 335/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0259 - val_loss: 1.0901\n",
            "Epoch 336/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0918\n",
            "Epoch 337/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0910\n",
            "Epoch 338/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0919\n",
            "Epoch 339/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0906\n",
            "Epoch 340/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0902\n",
            "Epoch 341/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0920\n",
            "Epoch 342/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0257 - val_loss: 1.0918\n",
            "Epoch 343/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0257 - val_loss: 1.0912\n",
            "Epoch 344/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0923\n",
            "Epoch 345/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0906\n",
            "Epoch 346/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0258 - val_loss: 1.0924\n",
            "Epoch 347/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0915\n",
            "Epoch 348/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0258 - val_loss: 1.0924\n",
            "Epoch 349/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0904\n",
            "Epoch 350/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0919\n",
            "Epoch 351/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0918\n",
            "Epoch 352/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0257 - val_loss: 1.0916\n",
            "Epoch 353/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0912\n",
            "Epoch 354/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0909\n",
            "Epoch 355/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0922\n",
            "Epoch 356/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0912\n",
            "Epoch 357/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0912\n",
            "Epoch 358/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0257 - val_loss: 1.0926\n",
            "Epoch 359/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0256 - val_loss: 1.0922\n",
            "Epoch 360/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0256 - val_loss: 1.0921\n",
            "Epoch 361/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0916\n",
            "Epoch 362/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0923\n",
            "Epoch 363/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0911\n",
            "Epoch 364/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0257 - val_loss: 1.0929\n",
            "Epoch 365/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0922\n",
            "Epoch 366/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0256 - val_loss: 1.0924\n",
            "Epoch 367/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0257 - val_loss: 1.0916\n",
            "Epoch 368/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0257 - val_loss: 1.0931\n",
            "Epoch 369/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0256 - val_loss: 1.0889\n",
            "Epoch 370/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0930\n",
            "Epoch 371/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0913\n",
            "Epoch 372/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0257 - val_loss: 1.0920\n",
            "Epoch 373/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0923\n",
            "Epoch 374/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0256 - val_loss: 1.0926\n",
            "Epoch 375/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0256 - val_loss: 1.0925\n",
            "Epoch 376/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0256 - val_loss: 1.0923\n",
            "Epoch 377/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0256 - val_loss: 1.0914\n",
            "Epoch 378/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0256 - val_loss: 1.0928\n",
            "Epoch 379/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0910\n",
            "Epoch 380/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0920\n",
            "Epoch 381/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0256 - val_loss: 1.0922\n",
            "Epoch 382/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0256 - val_loss: 1.0927\n",
            "Epoch 383/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0925\n",
            "Epoch 384/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0254 - val_loss: 1.0926\n",
            "Epoch 385/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0943\n",
            "Epoch 386/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0256 - val_loss: 1.0930\n",
            "Epoch 387/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0930\n",
            "Epoch 388/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0935\n",
            "Epoch 389/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0930\n",
            "Epoch 390/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0937\n",
            "Epoch 391/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0925\n",
            "Epoch 392/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0928\n",
            "Epoch 393/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0255 - val_loss: 1.0929\n",
            "Epoch 394/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0255 - val_loss: 1.0943\n",
            "Epoch 395/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0930\n",
            "Epoch 396/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0953\n",
            "Epoch 397/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0941\n",
            "Epoch 398/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0955\n",
            "Epoch 399/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0937\n",
            "Epoch 400/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0957\n",
            "Epoch 401/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0931\n",
            "Epoch 402/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0948\n",
            "Epoch 403/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0937\n",
            "Epoch 404/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0946\n",
            "Epoch 405/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0255 - val_loss: 1.0946\n",
            "Epoch 406/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0255 - val_loss: 1.0950\n",
            "Epoch 407/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0945\n",
            "Epoch 408/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0942\n",
            "Epoch 409/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0254 - val_loss: 1.0944\n",
            "Epoch 410/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0254 - val_loss: 1.0948\n",
            "Epoch 411/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0930\n",
            "Epoch 412/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0962\n",
            "Epoch 413/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0946\n",
            "Epoch 414/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0946\n",
            "Epoch 415/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0253 - val_loss: 1.0958\n",
            "Epoch 416/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0950\n",
            "Epoch 417/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0950\n",
            "Epoch 418/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0954\n",
            "Epoch 419/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0254 - val_loss: 1.0946\n",
            "Epoch 420/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0946\n",
            "Epoch 421/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0958\n",
            "Epoch 422/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0254 - val_loss: 1.0946\n",
            "Epoch 423/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0953\n",
            "Epoch 424/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0960\n",
            "Epoch 425/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0965\n",
            "Epoch 426/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0253 - val_loss: 1.0964\n",
            "Epoch 427/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0253 - val_loss: 1.0952\n",
            "Epoch 428/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0254 - val_loss: 1.0959\n",
            "Epoch 429/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0253 - val_loss: 1.0957\n",
            "Epoch 430/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0253 - val_loss: 1.0955\n",
            "Epoch 431/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0956\n",
            "Epoch 432/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0253 - val_loss: 1.0957\n",
            "Epoch 433/500\n",
            "75627/75627 [==============================] - 5s 67us/step - loss: 0.0253 - val_loss: 1.0952\n",
            "Epoch 434/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0253 - val_loss: 1.0966\n",
            "Epoch 435/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0253 - val_loss: 1.0947\n",
            "Epoch 436/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0253 - val_loss: 1.0956\n",
            "Epoch 437/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0253 - val_loss: 1.0962\n",
            "Epoch 438/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0965\n",
            "Epoch 439/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0960\n",
            "Epoch 440/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0973\n",
            "Epoch 441/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0937\n",
            "Epoch 442/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0973\n",
            "Epoch 443/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0253 - val_loss: 1.0943\n",
            "Epoch 444/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0961\n",
            "Epoch 445/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0950\n",
            "Epoch 446/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0955\n",
            "Epoch 447/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0943\n",
            "Epoch 448/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0253 - val_loss: 1.0959\n",
            "Epoch 449/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0949\n",
            "Epoch 450/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0251 - val_loss: 1.0966\n",
            "Epoch 451/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0959\n",
            "Epoch 452/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0965\n",
            "Epoch 453/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0944\n",
            "Epoch 454/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0962\n",
            "Epoch 455/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0956\n",
            "Epoch 456/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0953\n",
            "Epoch 457/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0962\n",
            "Epoch 458/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0952\n",
            "Epoch 459/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0970\n",
            "Epoch 460/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0956\n",
            "Epoch 461/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0958\n",
            "Epoch 462/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0251 - val_loss: 1.0971\n",
            "Epoch 463/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0960\n",
            "Epoch 464/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0252 - val_loss: 1.0968\n",
            "Epoch 465/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0253 - val_loss: 1.0975\n",
            "Epoch 466/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0958\n",
            "Epoch 467/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0967\n",
            "Epoch 468/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0976\n",
            "Epoch 469/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0963\n",
            "Epoch 470/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0964\n",
            "Epoch 471/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0961\n",
            "Epoch 472/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0960\n",
            "Epoch 473/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0953\n",
            "Epoch 474/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0966\n",
            "Epoch 475/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0961\n",
            "Epoch 476/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0966\n",
            "Epoch 477/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0251 - val_loss: 1.0964\n",
            "Epoch 478/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0250 - val_loss: 1.0968\n",
            "Epoch 479/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0252 - val_loss: 1.0953\n",
            "Epoch 480/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0960\n",
            "Epoch 481/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0952\n",
            "Epoch 482/500\n",
            "75627/75627 [==============================] - 5s 64us/step - loss: 0.0251 - val_loss: 1.0968\n",
            "Epoch 483/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0962\n",
            "Epoch 484/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0965\n",
            "Epoch 485/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0959\n",
            "Epoch 486/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0955\n",
            "Epoch 487/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0964\n",
            "Epoch 488/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0945\n",
            "Epoch 489/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0252 - val_loss: 1.0967\n",
            "Epoch 490/500\n",
            "75627/75627 [==============================] - 5s 61us/step - loss: 0.0250 - val_loss: 1.0944\n",
            "Epoch 491/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0250 - val_loss: 1.0966\n",
            "Epoch 492/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0954\n",
            "Epoch 493/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0965\n",
            "Epoch 494/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0250 - val_loss: 1.0952\n",
            "Epoch 495/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0251 - val_loss: 1.0954\n",
            "Epoch 496/500\n",
            "75627/75627 [==============================] - 5s 62us/step - loss: 0.0251 - val_loss: 1.0953\n",
            "Epoch 497/500\n",
            "75627/75627 [==============================] - 5s 65us/step - loss: 0.0251 - val_loss: 1.0948\n",
            "Epoch 498/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0251 - val_loss: 1.0968\n",
            "Epoch 499/500\n",
            "75627/75627 [==============================] - 5s 66us/step - loss: 0.0250 - val_loss: 1.0954\n",
            "Epoch 500/500\n",
            "75627/75627 [==============================] - 5s 63us/step - loss: 0.0250 - val_loss: 1.0950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX0VzrFddXJO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}